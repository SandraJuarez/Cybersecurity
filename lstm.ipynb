{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series classification of anomaly detections\n",
    "===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1930948ba10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No.      Time      Source Destination Protocol  Length  \\\n",
      "0  135  1.183043  10.10.10.9     9.9.9.9      DNS      89   \n",
      "1  138  1.192994     9.9.9.9  10.10.10.9      DNS     224   \n",
      "2  429  2.984566  10.10.10.9     9.9.9.9      DNS      84   \n",
      "3  430  2.995903     9.9.9.9  10.10.10.9      DNS     231   \n",
      "4  601  3.632943  10.10.10.9     9.9.9.9      DNS      77   \n",
      "\n",
      "                                                Info  \n",
      "0  Standard query 0xe181 A nav.smartscreen.micros...  \n",
      "1  Standard query response 0xe181 A nav.smartscre...  \n",
      "2   Standard query 0x0ac6 A afdxtest.z01.azurefd.net  \n",
      "3  Standard query response 0x0ac6 A afdxtest.z01....  \n",
      "4          Standard query 0x2151 A k-ring.msedge.net  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('test2.csv')\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No.      Time   Source Destination Protocol  Length  \\\n",
      "0  135  1.183043  1010109        9999      DNS      89   \n",
      "1  138  1.192994     9999     1010109      DNS     224   \n",
      "2  429  2.984566  1010109        9999      DNS      84   \n",
      "3  430  2.995903     9999     1010109      DNS     231   \n",
      "4  601  3.632943  1010109        9999      DNS      77   \n",
      "\n",
      "                                                Info  \n",
      "0  Standard query 0xe181 A nav.smartscreen.micros...  \n",
      "1  Standard query response 0xe181 A nav.smartscre...  \n",
      "2   Standard query 0x0ac6 A afdxtest.z01.azurefd.net  \n",
      "3  Standard query response 0x0ac6 A afdxtest.z01....  \n",
      "4          Standard query 0x2151 A k-ring.msedge.net  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52333\\AppData\\Local\\Temp\\ipykernel_19032\\3143322765.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Source'] = df['Source'].str.replace('.', '')\n",
      "C:\\Users\\52333\\AppData\\Local\\Temp\\ipykernel_19032\\3143322765.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Destination'] = df['Destination'].str.replace('.', '')\n"
     ]
    }
   ],
   "source": [
    "df['Source'] = df['Source'].str.replace('.', '')\n",
    "df['Destination'] = df['Destination'].str.replace('.', '')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame con la columna 'Source' modificada\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time   Source Destination  Length\n",
      "0  1.183043  1010109        9999      89\n",
      "1  1.192994     9999     1010109     224\n",
      "2  2.984566  1010109        9999      84\n",
      "3  2.995903     9999     1010109     231\n",
      "4  3.632943  1010109        9999      77\n"
     ]
    }
   ],
   "source": [
    "protocol_mapping = {\n",
    "    'TCP': 1,\n",
    "    'UDP': 2,\n",
    "    'HTTP': 3,\n",
    "    'HTTPS': 4,\n",
    "    'FTP': 5,\n",
    "    'SMTP': 6,\n",
    "    'POP3': 7,\n",
    "    'IMAP': 8,\n",
    "    'SNMP': 9,\n",
    "    'DHCP': 10,\n",
    "    'DNS': 11,\n",
    "    'ICMP':12\n",
    "}\n",
    "\n",
    "df['Protocol'] = df['Protocol'].replace(protocol_mapping)\n",
    "df = df.drop(columns=['Info','No.'])\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame con la columna 'Protocol' modificada\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we split our dataset into training and validation data\n",
    "========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "  df,\n",
    "  test_size=0.15,\n",
    "  random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "  df,\n",
    "  test_size=0.33, \n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "\n",
    "  sequences = df.astype(np.float32).to_numpy().tolist()\n",
    "\n",
    "  dataset = [torch.tensor(s).unsqueeze(1).float() for s in sequences]\n",
    "\n",
    "  n_seq, seq_len, n_features = torch.stack(dataset).shape\n",
    "\n",
    "  return dataset, seq_len, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, seq_len, n_features = create_dataset(train_df)\n",
    "val_dataset, _, _ = create_dataset(val_df)\n",
    "test_normal_dataset, _, _ = create_dataset(test_df)\n",
    "#test_anomaly_dataset, _, _ = create_dataset(anomaly_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the class of the Autoencoder with an Lstm\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.seq_len, self.n_features = seq_len, n_features\n",
    "    self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "\n",
    "    self.rnn1 = nn.LSTM(\n",
    "      input_size=n_features,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "    \n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=self.hidden_dim,\n",
    "      hidden_size=embedding_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.reshape((1, self.seq_len, self.n_features))\n",
    "\n",
    "    x, (_, _) = self.rnn1(x)\n",
    "    x, (hidden_n, _) = self.rnn2(x)\n",
    "\n",
    "    return hidden_n.reshape((self.n_features, self.embedding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, seq_len, input_dim=64, n_features=1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.seq_len, self.input_dim = seq_len, input_dim\n",
    "    self.hidden_dim, self.n_features = 2 * input_dim, n_features\n",
    "\n",
    "    self.rnn1 = nn.LSTM(\n",
    "      input_size=input_dim,\n",
    "      hidden_size=input_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "\n",
    "    self.rnn2 = nn.LSTM(\n",
    "      input_size=input_dim,\n",
    "      hidden_size=self.hidden_dim,\n",
    "      num_layers=1,\n",
    "      batch_first=True\n",
    "    )\n",
    "\n",
    "    self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.repeat(self.seq_len, self.n_features)\n",
    "    x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "\n",
    "    x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "    x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "    x = x.reshape((self.seq_len, self.hidden_dim))\n",
    "\n",
    "    return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the Encoder-Decoder\n",
    "================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "\n",
    "  def __init__(self, seq_len, n_features, embedding_dim=14):\n",
    "    super(RecurrentAutoencoder, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "    self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    x = self.decoder(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentAutoencoder(seq_len, n_features)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "===========\n",
    "We train our model to minimize the loss function at the validation stagee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, val_dataset, n_epochs):\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "  criterion = nn.L1Loss(reduction='sum').to(device)\n",
    "  history = dict(train=[], val=[])\n",
    "\n",
    "  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "  best_loss = 10000.0\n",
    "  \n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    model = model.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for seq_true in train_dataset:\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      seq_true = seq_true.to(device)\n",
    "      seq_pred = model(seq_true)\n",
    "\n",
    "      loss = criterion(seq_pred, seq_true)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_losses.append(loss.item())\n",
    "\n",
    "    val_losses = []\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "      for seq_true in val_dataset:\n",
    "\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "\n",
    "        loss = criterion(seq_pred, seq_true)\n",
    "        val_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    history['train'].append(train_loss)\n",
    "    history['val'].append(val_loss)\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "      best_loss = val_loss\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n",
    "\n",
    "  model.load_state_dict(best_model_wts)\n",
    "  return model.eval(), history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss 73706423.82356195 val loss 74206237.67134832\n",
      "Epoch 2: train loss 73706389.64767699 val loss 74206209.70119382\n",
      "Epoch 3: train loss 73706363.18611726 val loss 74206182.99964887\n",
      "Epoch 4: train loss 73706338.0721792 val loss 74206157.52844101\n",
      "Epoch 5: train loss 73706314.51659292 val loss 74206132.2082163\n",
      "Epoch 6: train loss 73706291.22400442 val loss 74206111.15660113\n",
      "Epoch 7: train loss 73706266.55945796 val loss 74206089.45189607\n",
      "Epoch 8: train loss 73706243.46266593 val loss 74206065.00842696\n",
      "Epoch 9: train loss 73706220.61144912 val loss 74206040.85147472\n",
      "Epoch 10: train loss 73706198.35702434 val loss 74206016.62886237\n",
      "Epoch 11: train loss 73706177.53207965 val loss 74205999.86200842\n",
      "Epoch 12: train loss 73706159.20353982 val loss 74205985.18820225\n",
      "Epoch 13: train loss 73706144.49363938 val loss 74205968.25983146\n",
      "Epoch 14: train loss 73706131.20271018 val loss 74205956.47155899\n",
      "Epoch 15: train loss 73706118.69800885 val loss 74205945.33602528\n"
     ]
    }
   ],
   "source": [
    "model, history = train_model(\n",
    "  model, \n",
    "  train_dataset, \n",
    "  val_dataset, \n",
    "  n_epochs=15\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
